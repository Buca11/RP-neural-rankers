{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install required dependencies\n",
    "\n",
    "%pip install python-terrier==0.10.0  ir_measures ir_datasets fast-forward-indexes==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "from pathlib import Path\n",
    "from fast_forward.encoder import TCTColBERTQueryEncoder, TCTColBERTDocumentEncoder\n",
    "from fast_forward.util.pyterrier import FFScore, FFInterpolate\n",
    "from fast_forward import OnDiskIndex, Mode, Ranking\n",
    "from pyterrier.measures import RR, nDCG, MAP, AP, R\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "dataset_name = 'irds:beir/fiqa'\n",
    "dataset = pt.get_dataset(dataset_name)\n",
    "#Create lexical index for BM25 - stores index files locally\n",
    "indexer = pt.IterDictIndexer(\n",
    "str(Path.cwd()),\n",
    "meta={'docno': 7})\n",
    "indexer.index(dataset.get_corpus_iter(), fields=['text'])\n",
    "#Create index from local directory\n",
    "index = pt.IndexFactory.of(str(Path.cwd()), memory=True)\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devset_name = 'irds:beir/fiqa/dev'\n",
    "devset = pt.get_dataset(devset_name)\n",
    "#Retrieve 1000 documents using BM25 and write the results to file\n",
    "candidates = (bm25 % 1000)(devset.get_topics())\n",
    "pt.io.write_results(candidates,'trec-run-bm25_fiqa-dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TCT ColBERT Hyperparameter tuning\n",
    "\n",
    "def docs_iter(dataset):\n",
    "    for d in dataset.get_corpus_iter():\n",
    "        yield {\"doc_id\": d[\"docno\"], \"text\": d[\"text\"]}\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "q_encoder = TCTColBERTQueryEncoder(\"castorini/tct_colbert-msmarco\")\n",
    "d_encoder = TCTColBERTDocumentEncoder(\n",
    "    \"castorini/tct_colbert-msmarco\",\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "#Create Fast Forward index\n",
    "ff_index = OnDiskIndex(Path(\"ffindex_fiqa_tct.h5\"), dim=768, query_encoder=q_encoder, mode=Mode.MAXP)\n",
    "#Load index from disk \n",
    "# ff_index = OnDiskIndex.load(\n",
    "#     Path(\"/projects/neural_ranking/ff_indexes/tct_colbert/ff_msmarco-v1-passage.tct_colbert.h5\"),  query_encoder=q_encoder, mode=Mode.MAXP\n",
    "# )\n",
    "ff_index = ff_index.to_memory()\n",
    "ff_score = FFScore(ff_index)\n",
    "re_ranked = ff_score(candidates)\n",
    "ff_int = FFInterpolate(alpha=0.5)\n",
    "#Hyperparameter tuning to find alpha for interpolation\n",
    "df: pd.DataFrame = pt.GridSearch(bm25 % 1000 >> ff_score >> ff_int,\n",
    "{ff_int: {\"alpha\": [0.05, 0.1, 0.25,0.5, 0.75,0.9]}},\n",
    "devset.get_topics(),\n",
    "devset.get_qrels(),\n",
    "\"ndcg_cut_10\",\n",
    "verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolation-based re-ranking results\n",
    "#best alpha\n",
    "print(ff_int.alpha)\n",
    "testset_name = 'irds:beir/fiqa/test'\n",
    "testset = pt.get_dataset(testset_name)\n",
    "#BM25 first-stage retrieval\n",
    "candidates = (bm25 % 1000)(testset.get_topics())\n",
    "pt.io.write_results(candidates,'trec-run-bm25_fiqa-test-0.1.txt')\n",
    "re_ranked = ff_score(candidates)\n",
    "ff_int = FFInterpolate(alpha=ff_int.alpha)\n",
    "# BM25-> TCT-ColBERT interpolation-based re-ranking\n",
    "res = ff_int(re_ranked)\n",
    "new_df = res[['qid', 'docno', 'score']].rename(columns={'qid': 'q_id', 'docno': 'id'})\n",
    "r = Ranking(new_df)\n",
    "#Save FF results\n",
    "r.save(Path(\"trec-run-ff-bm25-tct-fiqa-test-0.1.txt\"))\n",
    "#Conduct experiment + calculate the metrics\n",
    "df: pd.DataFrame = pt.Experiment(\n",
    "[bm25, bm25 % 1000 >> ff_score >> ff_int],\n",
    "testset.get_topics(),\n",
    "testset.get_qrels(),\n",
    "eval_metrics=[RR @ 10, nDCG @ 10, R@ 100],\n",
    "names=[\"BM25\", \"BM25 to TCT\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
